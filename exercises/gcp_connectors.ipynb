{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "from pandas.io.json import build_table_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Bucket Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bucket(bucket_name:str, project_id:str):\n",
    "    \"\"\" A function that creates a bucket on GCP project\n",
    "\tParams:\n",
    "\t\tbucket_name: The bucket name to be created in GCP.\n",
    "\t\tproject_id:  The GCP project id were the bucket will be created.\n",
    "\n",
    "\tReturn: None\n",
    "    \"\"\"\n",
    "    \n",
    "    storage_client = storage.Client(project=project_id)\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    bucket.storage_class = \"COLDLINE\"\n",
    "    new_bucket = storage_client.create_bucket(bucket, project=project_id, location=\"us\")\n",
    "    \n",
    "    print(\n",
    "        f\"\"\"Bucket criado {new_bucket.name}\n",
    "        na location {new_bucket.location}\n",
    "        com storage class {new_bucket.storage_class}\"\"\")\n",
    "    \n",
    "    return new_bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket criado gcp-connectors-test\n",
      "        na location US\n",
      "        com storage class COLDLINE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Bucket: gcp-connectors-test>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_bucket(bucket_name=\"gcp-connectors-test\", project_id=\"gavb-poc-bu-mlops-f-store\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a bq dataset test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bq_dataset(dataset_name:str, project_id:str):\n",
    "\n",
    "\t\"\"\" A function that creates a dataset on bigquery to a specific project on GCP\n",
    "\n",
    "    Params:\n",
    "        dataset_name: the datset name to be created in GCP\n",
    "        project_id: The GCP project id were the bucket will be created.\n",
    "\n",
    "    Return: None\n",
    "\t\"\"\"\n",
    "\n",
    "\t# Estaciando o client do bigquery \n",
    "\tclient = bigquery.Client(project=project_id)\n",
    "\n",
    "\t# Criando dataset_id\n",
    "\tdataset_id = f\"{client.project}.{dataset_name}\"\n",
    "\n",
    "\t# Criando o dataset no bigquery\n",
    "\tdataset = bigquery.Dataset(dataset_id)\n",
    "\tdataset.location = \"US\"\n",
    "\tdataset = client.create_dataset(dataset, timeout=30)\n",
    "\n",
    "\tprint(f\"Dataset criado {client.project}.{dataset.dataset_id}\")\n",
    "\n",
    "\treturn dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset criado gavb-poc-bu-mlops-f-store.gcp_connector_dataset_test\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset(DatasetReference('gavb-poc-bu-mlops-f-store', 'gcp_connector_dataset_test'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_bq_dataset(dataset_name=\"gcp_connector_dataset_test\", project_id=\"gavb-poc-bu-mlops-f-store\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insertion data and create a new table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bq_select_create(project_id: str,\n",
    "                     query: str = None,\n",
    "                     df_to_bq: pd.DataFrame = None,\n",
    "                     dataset: str = None,\n",
    "                     destination_table: str = None,\n",
    "                     sql_type: str = \"SELECT\",\n",
    "                     verbose: bool = False\n",
    "                     )-> pd.DataFrame: \n",
    "    \n",
    "    \"\"\" A function to retrieve data from bigquery as a pandas dataframe and \n",
    "        to create a table from a pandas dataframe on bigquery. \n",
    "\n",
    "    Params:\n",
    "        query:             The sql query\n",
    "        project_id:        The GCP project id were the bucket will be created. \n",
    "        df_to_bq:          The dataframe from were the bq table will be created.\n",
    "        dataset:           The name of the dataset in bigquery.\n",
    "        destination_table: The path were the new bq talble will be created. In the form projectId.datasetId.tableId\n",
    "        sql_type:          If the operation is going to be `SELECT` to retrieve data or `CREATE` to create a new table.\n",
    "        verbose:           Enable logging.\n",
    "    \n",
    "    Return:\n",
    "        dataframe: A Dataframe object with the result of the query\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Teste do tipo do parametro sql_type\n",
    "    if  isinstance(sql_type, str):\n",
    "            sql_type = sql_type\n",
    "    else:\n",
    "        raise Exception(\"Argument sql_type must be a string\")\n",
    "\n",
    "    # Client\n",
    "    bq_client = bigquery.Client(project=project_id)\n",
    "\n",
    "    if sql_type == 'SELECT':\n",
    "\n",
    "        # Retriving the data\n",
    "        if verbose:\n",
    "            logging.debug(query)\n",
    "        data = (\n",
    "            bq_client.query(query)\n",
    "            .result()\n",
    "            .to_dataframe(create_bqstorage_client=True)\n",
    "        )\n",
    "        \n",
    "        return data\n",
    "\n",
    "    elif sql_type == 'CREATE':\n",
    "\n",
    "        destination_table = f'{project_id}.{dataset}.{destination_table}'\n",
    "        df_to_bq.to_gbq(destination_table=destination_table, project_id=project_id, if_exists=\"fail\")\n",
    "        \n",
    "        if verbose:\n",
    "\n",
    "            logging.debug(query)\n",
    "            print(f\"Created table {destination_table} at project {project_id}\")\n",
    "    else:\n",
    "\n",
    "        raise Exception(f\"Forbidden operation the parameter sql_type shoulbe either SELECT or CREATE.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created table gavb-poc-bu-mlops-f-store.gcp_connector_dataset_test.table_connectors_test at project gavb-poc-bu-mlops-f-store\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame({\"Coluna1\":[1], \"Coluna2\":[2]})\n",
    "\n",
    "bq_select_create(project_id=\"gavb-poc-bu-mlops-f-store\",\n",
    "                 df_to_bq=data,\n",
    "                 destination_table=\"table_connectors_test\",\n",
    "                 dataset=\"gcp_connector_dataset_test\",\n",
    "                 sql_type=\"CREATE\",\n",
    "                 verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coluna1</th>\n",
       "      <th>Coluna2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Coluna1  Coluna2\n",
       "0        1        2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bq_select_create(project_id=\"gavb-poc-bu-mlops-f-store\",\n",
    "                 query=\"select * from `gavb-poc-bu-mlops-f-store.gcp_connector_dataset_test.table_connectors_test` limit 10\",\n",
    "                 sql_type=\"SELECT\",\n",
    "                 verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "749e40b606625bb0c3425579147b49da7da3b1dc7431857946d8cd5b32b8cb13"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
